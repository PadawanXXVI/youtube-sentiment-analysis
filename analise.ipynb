{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1351d842",
   "metadata": {},
   "source": [
    "\n",
    "# üß† Fase 2 ‚Äî An√°lise de Sentimentos (Portugu√™s)  \n",
    "**Projeto:** Minera√ß√£o de Textos ‚Äî An√°lise de Sentimentos  \n",
    "**CRISP-DM:** Modeling / Evaluation  \n",
    "\n",
    "Este notebook l√™ o CSV gerado na Fase 1, realiza **limpeza**, **detec√ß√£o de idioma** e aplica um **modelo BERT-PT** para classificar **positivo/negativo/neutro**.  \n",
    "Foi preparado para uso **aut√¥nomo** e para futura **integra√ß√£o com Flask** (sem `input()`), salvando a sa√≠da com **timestamp**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02da27c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 1) Importa√ß√µes e par√¢metros\n",
    "# ============================================================\n",
    "import os, re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import emoji\n",
    "from langdetect import detect, DetectorFactory\n",
    "from transformers import pipeline\n",
    "from glob import glob\n",
    "\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "INPUT_PATH = os.getenv(\"INPUT_PATH\", \"data/comentarios_coletados_*.csv\")  # curinga tratado abaixo\n",
    "OUTPUT_DIR = os.getenv(\"OUTPUT_DIR\", \"resultados\")\n",
    "HF_MODEL_PT = os.getenv(\"HF_MODEL_PT\", \"pierreguillou/bert-base-cased-sentiment-br\")\n",
    "\n",
    "print(\"‚úÖ Bibliotecas carregadas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb47b6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 2) Descoberta autom√°tica do √∫ltimo arquivo de coleta\n",
    "# ============================================================\n",
    "def ultimo_csv_coleta(pattern: str = \"data/comentarios_coletados_*.csv\") -> str:\n",
    "    arquivos = sorted(glob(pattern))\n",
    "    if not arquivos:\n",
    "        raise FileNotFoundError(\"Nenhum arquivo de coleta encontrado. Execute a Fase 1 antes.\")\n",
    "    return arquivos[-1]\n",
    "\n",
    "if \"*\" in INPUT_PATH:\n",
    "    INPUT_PATH = ultimo_csv_coleta(INPUT_PATH)\n",
    "\n",
    "print(f\"üì• Lendo dados de: {INPUT_PATH}\")\n",
    "df = pd.read_csv(INPUT_PATH)\n",
    "print(f\"Registros carregados: {len(df)}\")\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5b81dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 3) Limpeza e normaliza√ß√£o de texto\n",
    "# ============================================================\n",
    "def limpar_texto(texto: str) -> str:\n",
    "    import re, emoji\n",
    "    t = emoji.demojize(str(texto))\n",
    "    t = re.sub(r\"http\\S+|www\\.\\S+\", \" \", t)\n",
    "    t = re.sub(r\"@[A-Za-z0-9_]+|#[A-Za-z0-9_]+\", \" \", t)\n",
    "    t = re.sub(r\"[^A-Za-z√Ä-√ø\\s:]\", \" \", t)\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n",
    "    return t\n",
    "\n",
    "df[\"comentario_limpo\"] = df[\"comentario\"].astype(str).apply(limpar_texto)\n",
    "df = df[df[\"comentario_limpo\"].str.len() > 3].copy()\n",
    "\n",
    "print(\"üßπ Limpeza conclu√≠da.\")\n",
    "display(df[[\"video_titulo\",\"comentario\",\"comentario_limpo\"]].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63733699",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 4) Detec√ß√£o de idioma e filtro (PT)\n",
    "# ============================================================\n",
    "def detectar_idioma_seguro(texto: str) -> str:\n",
    "    try:\n",
    "        return detect(texto)\n",
    "    except Exception:\n",
    "        return \"indefinido\"\n",
    "\n",
    "df[\"idioma\"] = df[\"comentario_limpo\"].apply(detectar_idioma_seguro)\n",
    "df_pt = df[df[\"idioma\"] == \"pt\"].copy()\n",
    "\n",
    "print(f\"Total ap√≥s limpeza: {len(df)} | Em portugu√™s: {len(df_pt)}\")\n",
    "display(df_pt.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29291c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 5) Pipeline HuggingFace (PT-BR) ‚Äî com batch\n",
    "# ============================================================\n",
    "sentiment_pt = pipeline(\n",
    "    task=\"sentiment-analysis\",\n",
    "    model=HF_MODEL_PT,\n",
    "    truncation=True,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "def padronizar_label(lbl: str) -> str:\n",
    "    m = {\"POS\": \"positivo\", \"positive\": \"positivo\",\n",
    "         \"NEG\": \"negativo\", \"negative\": \"negativo\",\n",
    "         \"NEU\": \"neutro\",   \"neutral\":  \"neutro\"}\n",
    "    return m.get(lbl, lbl)\n",
    "\n",
    "preds = sentiment_pt(df_pt[\"comentario_limpo\"].tolist())\n",
    "df_pt[\"sentimento\"] = [padronizar_label(p[\"label\"]) for p in preds]\n",
    "df_pt[\"score\"] = [p[\"score\"] for p in preds]\n",
    "\n",
    "print(\"‚úÖ An√°lise conclu√≠da.\")\n",
    "display(df_pt[[\"video_titulo\",\"comentario_limpo\",\"sentimento\",\"score\"]].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43263520",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 6) Gr√°ficos b√°sicos\n",
    "# ============================================================\n",
    "if not df_pt.empty:\n",
    "    dist = df_pt[\"sentimento\"].value_counts().sort_index()\n",
    "    plt.figure(figsize=(6,4))\n",
    "    dist.plot(kind=\"bar\")\n",
    "    plt.title(\"Distribui√ß√£o de Sentimentos (PT)\")\n",
    "    plt.xlabel(\"Sentimento\")\n",
    "    plt.ylabel(\"Quantidade\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    por_video = df_pt.groupby([\"video_titulo\",\"sentimento\"]).size().unstack(fill_value=0)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    por_video.plot(kind=\"bar\", stacked=True)\n",
    "    plt.title(\"Sentimentos por V√≠deo (PT)\")\n",
    "    plt.xlabel(\"V√≠deo\")\n",
    "    plt.ylabel(\"Quantidade\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Sem dados em PT para gr√°ficos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260b2e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 7) Exporta√ß√£o com timestamp\n",
    "# ============================================================\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "ts = pd.Timestamp.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "out_path = os.path.join(OUTPUT_DIR, f\"comentarios_analisados_{ts}.csv\")\n",
    "df_pt.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"üì¶ Salvo em: {out_path} | Linhas: {len(df_pt)}\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
