{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f0d4d17",
   "metadata": {},
   "source": [
    "\n",
    "# üé• FASE 1 ‚Äì Coleta de Coment√°rios do YouTube  \n",
    "**Projeto:** An√°lise de Sentimentos em Coment√°rios de V√≠deos  \n",
    "**Etapa do CRISP-DM:** Data Acquisition  \n",
    "\n",
    "Este notebook coleta coment√°rios dos v√≠deos mais visualizados de um canal do YouTube, aplicando boas pr√°ticas de pagina√ß√£o, detec√ß√£o de idioma e exporta√ß√£o em CSV.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e356719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 1Ô∏è‚É£ Importa√ß√£o das bibliotecas\n",
    "# ============================================================\n",
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "import time, os\n",
    "from dotenv import load_dotenv\n",
    "from langdetect import detect, DetectorFactory\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Garante reprodutibilidade na detec√ß√£o de idioma\n",
    "DetectorFactory.seed = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a0dd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 2Ô∏è‚É£ Configura√ß√µes iniciais e conex√£o com a API\n",
    "# ============================================================\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"YOUTUBE_API_KEY\")\n",
    "channel_id = os.getenv(\"CHANNEL_ID\")\n",
    "\n",
    "youtube = build(\"youtube\", \"v3\", developerKey=api_key)\n",
    "print(\"‚úÖ Conex√£o estabelecida com a API do YouTube!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df0966b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 3Ô∏è‚É£ Fun√ß√£o para extrair coment√°rios com pagina√ß√£o e tratamento de erros\n",
    "# ============================================================\n",
    "def extrair_comentarios(video_id, max_comments=1000):\n",
    "    comentarios, token = [], None\n",
    "    try:\n",
    "        while True:\n",
    "            response = youtube.commentThreads().list(\n",
    "                part=\"snippet\",\n",
    "                videoId=video_id,\n",
    "                maxResults=100,\n",
    "                textFormat=\"plainText\",\n",
    "                pageToken=token\n",
    "            ).execute()\n",
    "\n",
    "            for item in response.get(\"items\", []):\n",
    "                texto = item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"]\n",
    "                comentarios.append(texto)\n",
    "\n",
    "            token = response.get(\"nextPageToken\")\n",
    "            if not token or len(comentarios) >= max_comments:\n",
    "                break\n",
    "            time.sleep(0.5)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erro ao buscar coment√°rios do v√≠deo {video_id}: {e}\")\n",
    "    return comentarios[:max_comments]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf4251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 4Ô∏è‚É£ Coleta dos v√≠deos mais visualizados do canal\n",
    "# ============================================================\n",
    "def coletar_comentarios_canal(channel_id, max_videos=5):\n",
    "    search = youtube.search().list(\n",
    "        part=\"id,snippet\",\n",
    "        channelId=channel_id,\n",
    "        maxResults=max_videos,\n",
    "        order=\"viewCount\",\n",
    "        type=\"video\"\n",
    "    ).execute()\n",
    "\n",
    "    dados = []\n",
    "    for item in search[\"items\"]:\n",
    "        video_id = item[\"id\"][\"videoId\"]\n",
    "        titulo = item[\"snippet\"][\"title\"]\n",
    "        coments = extrair_comentarios(video_id)\n",
    "        for c in coments:\n",
    "            try:\n",
    "                idioma = detect(c)\n",
    "            except:\n",
    "                idioma = \"indefinido\"\n",
    "            dados.append({\n",
    "                \"video_id\": video_id,\n",
    "                \"video_titulo\": titulo,\n",
    "                \"comentario\": c,\n",
    "                \"idioma\": idioma,\n",
    "                \"data_coleta\": pd.Timestamp.now().strftime(\"%Y-%m-%d\")\n",
    "            })\n",
    "    return pd.DataFrame(dados)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7881908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 5Ô∏è‚É£ Execu√ß√£o principal da coleta\n",
    "# ============================================================\n",
    "df = coletar_comentarios_canal(channel_id)\n",
    "print(\"‚úÖ Coleta conclu√≠da!\")\n",
    "print(f\"Total de v√≠deos analisados: {df['video_id'].nunique()}\")\n",
    "print(f\"Total de coment√°rios coletados: {len(df)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ee03f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 6Ô∏è‚É£ Tratamento final e exporta√ß√£o\n",
    "# ============================================================\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.to_csv(\"comentarios_top5.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"üìÇ Arquivo exportado: comentarios_top5.csv\")\n",
    "print(f\"Linhas salvas: {len(df)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c8986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 7Ô∏è‚É£ EDA b√°sica ‚Äì estat√≠sticas descritivas\n",
    "# ============================================================\n",
    "df['tamanho'] = df['comentario'].astype(str).str.len()\n",
    "print(\"\\nüìä Estat√≠sticas b√°sicas do tamanho dos coment√°rios:\")\n",
    "print(df['tamanho'].describe())\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "df['tamanho'].plot(kind='hist', bins=30, color='steelblue', edgecolor='black')\n",
    "plt.title(\"Distribui√ß√£o do Tamanho dos Coment√°rios\")\n",
    "plt.xlabel(\"N√∫mero de caracteres\")\n",
    "plt.ylabel(\"Frequ√™ncia\")\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f0aedb",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "‚úÖ **Notebook finalizado com sucesso!**  \n",
    "Coment√°rios coletados, limpos e salvos para uso na Fase 2 (An√°lise de Sentimentos).\n",
    "\n",
    "Pr√≥xima etapa: aplica√ß√£o de modelos de NLP (BERT em portugu√™s) para classificar os coment√°rios como positivos, negativos ou neutros.\n",
    "    "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
